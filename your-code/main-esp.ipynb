{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Índice de contenidos\n",
    "1. Antes de empezar:\n",
    "\n",
    "2. Reto 1 - Importar y describir el conjunto de datos\n",
    "\n",
    "    2.0.0.1 Explore el conjunto de datos con técnicas matemáticas y de visualización. ¿Qué encuentra?\n",
    "\n",
    "3. Reto 2 - Limpieza y transformación de datos\n",
    "\n",
    "4. Reto 3 - Preprocesamiento de datos\n",
    "\n",
    "    4.0.0.1 Utilizaremos el StandardScaler de sklearn.preprocessing y escalaremos nuestros datos. Lea más sobre StandardScaler aquí.\n",
    "\n",
    "5. Reto 4 - Agrupación de datos con K-Means\n",
    "\n",
    "6. Reto 5 - Agrupación de datos con DBSCAN\n",
    "\n",
    "7. Reto 6 - Comparar K-Means con DBSCAN\n",
    "\n",
    "8. Reto adicional 2 - Cambiar el número de clusters de K-Means\n",
    "\n",
    "9. Bonus Challenge 3 - Cambiar DBSCAN eps y min_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Antes de empezar:\n",
    "- Lee el archivo README.md\n",
    "- Comenta todo lo que puedas y utiliza los recursos del archivo README.md\n",
    "- ¡Feliz aprendizaje!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your libraries:\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings                                              \n",
    "from sklearn.exceptions import DataConversionWarning          \n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafío 1 - Importar y describir el conjunto de datos\n",
    "\n",
    "En este laboratorio, utilizaremos un conjunto de datos que contiene información sobre las preferencias de los clientes. Analizaremos cuánto gasta cada cliente en un año en cada subcategoría de la tienda de comestibles e intentaremos encontrar similitudes mediante la agrupación.\n",
    "\n",
    "El origen del conjunto de datos es [aquí](https://archive.ics.uci.edu/ml/datasets/wholesale+customers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data: Wholesale customers data\n",
    "whole = pd.read_csv('../data/Wholesale customers data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explora el conjunto de datos con técnicas matemáticas y de visualización. ¿Qué encuentras?\n",
    "\n",
    "Lista de comprobación:\n",
    "\n",
    "* ¿Qué significa cada columna?\n",
    "* ¿Hay datos categóricos que convertir?\n",
    "* ¿Hay que eliminar datos que faltan?\n",
    "* Colinealidad de columnas: ¿hay correlaciones altas?\n",
    "* Estadísticas descriptivas: ¿hay que eliminar algún valor atípico?\n",
    "* Distribución de los datos por columnas: ¿está sesgada la distribución?\n",
    "* Etc.\n",
    "\n",
    "Información adicional: Hace más de un siglo, un economista italiano llamado Vilfredo Pareto descubrió que aproximadamente el 20% de los clientes representan el 80% de las ventas minoristas típicas. Esto se denomina [principio de Pareto](https://en.wikipedia.org/wiki/Pareto_principle). Compruebe si este conjunto de datos presenta esta característica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole.info()\n",
    "whole.Region.value_counts().sort_index()\n",
    "whole.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numericals = whole.select_dtypes(np.number)\n",
    "corr = numericals.corr()\n",
    "display(corr)\n",
    "# Create a heatmap to visualize the correlation matrix\n",
    "sns.set_context(\"poster\") # Set the Seaborn context to \"poster\" for larger text and figures\n",
    "sns.set(rc={\"figure.figsize\": (12., 6.)}) # Set the default figure size for Seaborn plots\n",
    "sns.set_style(\"whitegrid\") # Set the Seaborn style to \"whitegrid\" for a white background with gridlines\n",
    "sns.heatmap(corr.round(2), annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 6, figsize=(15, 6), sharey=True)\n",
    "sns.boxplot(y='Fresh', data=whole, ax=axs[0])\n",
    "axs[0].set_title('Fresh')\n",
    "axs[0].set_ylabel('m.u.')\n",
    "sns.boxplot(y='Milk', data=whole, ax=axs[1])\n",
    "axs[1].set_title('Milk')\n",
    "sns.boxplot(y='Grocery', data=whole, ax=axs[2])\n",
    "axs[2].set_title('Grocery')\n",
    "sns.boxplot(y='Frozen', data=whole, ax=axs[3])\n",
    "axs[3].set_title('Frozen')\n",
    "sns.boxplot(y='Detergents_Paper', data=whole, ax=axs[4])\n",
    "axs[4].set_title('Detergents_Paper')\n",
    "sns.boxplot(y='Delicassen', data=whole, ax=axs[5])\n",
    "axs[5].set_title('Delicassen')\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) #rect=[left, bottom, right, top]\n",
    "fig.suptitle('Continuous features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVACIONES:**\n",
    "\n",
    "+ Channel: columna categórica con dos valores posibles, Horeca (Hotel/Restaurant/Café) o Retail.\n",
    ">```terminal\n",
    ">Channel\n",
    ">1    298    Horeca\n",
    ">2    142    Retail\n",
    ">```\n",
    "+ Region: columna target/etiqueta, de tipo categórico, con Lisbon, Oporto o Other Region como valores posibles.\n",
    ">```terminal\n",
    ">Region\n",
    ">1     77   Lisbon\n",
    ">2     47   Oporto\n",
    ">3    316   Other Region\n",
    ">```\n",
    "+ Las demás columnas (Fresh, Milk, Grocery, Frozen, Detergents_Paper, Delicassen) son contínuas, de tipo _integer_, y representan el gasto anual en unidades de moneda o _monetary units_ (m.u.).\n",
    "\n",
    "\n",
    "+ Todos las columnas de valores continuos tienen una gran variabilidad (valor mínimo y máximo muy dispares).\n",
    "\n",
    "+ Los datos categóricos ya están en formato numérico; no hay que convertirlos.\n",
    "\n",
    "+ Tampoco faltan datos (no hay valores Null en ninguna columna; todas tienen 440 filas).\n",
    "\n",
    "+ Parece haber una alta correlación entre Grocery y Detergents_Paper (92%).\n",
    "\n",
    "+ Todas las características contínuas parecen tener valores atípicos, muy especialmente Fresh, con un valor que supera en más de 4 veces el valor promedio.\n",
    "\n",
    "+ El gasto en Frozen, Detergents_Paper y Delicassen es notoriamente más bajo que en el resto de productos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 2 - Limpieza y transformación de datos\n",
    "\n",
    "Si tu conclusión del reto anterior es que los datos necesitan limpieza/transformación, hazlo en las celdas de abajo. Sin embargo, si su conclusión es que los datos no necesitan ser limpiados o transformados, no dudes en saltarte este reto. Si optas por esta última opción, explica los motivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole[whole['Fresh']>4*whole['Fresh'].mean()].sort_values(by='Fresh', ascending=False)\n",
    "# whole[whole['Grocery']>4*whole['Grocery'].mean()].sort_values(by='Grocery', ascending=False)\n",
    "# whole[whole['Milk']>4*whole['Milk'].mean()].sort_values(by='Milk', ascending=False)\n",
    "# whole[whole['Frozen']>4*whole['Frozen'].mean()].sort_values(by='Frozen', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVACIONES**\n",
    "\n",
    "+ Aunque algunos valores de Fresh superan en más de 4 veces el promedio, puesto que esos datos están asociados a Other Regions, es posible que sean acumulados de varias ciudades/regiones y por tanto el dato sea válido. Lo mismo para el valor más atípico de Grocery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 3 - Preprocesamiento de datos\n",
    "\n",
    "Uno de los problemas del conjunto de datos es que los rangos de valores son notablemente diferentes en las distintas categorías (por ejemplo, `Fresh` y `Grocery` en comparación con `Detergents_Paper` y `Delicassen`). Si hiciste esta observación en el primer reto, ¡has hecho un gran trabajo! Esto significa que no sólo has completado las preguntas de bonificación en el anterior laboratorio de Aprendizaje Supervisado, sino que también has investigado en profundidad sobre [*feature scaling*](https://en.wikipedia.org/wiki/Feature_scaling). ¡Sigue trabajando así de bien!\n",
    "\n",
    "Diversos rangos de valores en diferentes características podrían causar problemas en nuestra agrupación. La forma de reducir el problema es mediante el escalado de características. Volveremos a utilizar esta técnica con este conjunto de datos.\n",
    "\n",
    "#### Utilizaremos el `StandardScaler` de `sklearn.preprocessing` y escalaremos nuestros datos. Lee más sobre `StandardScaler` [aquí](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler).\n",
    "\n",
    "*Después de escalar tus datos, asigna los datos transformados a una nueva variable `customers_scale`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = whole  # Feature data\n",
    "#y = None  # Target labels (not used in K-means clustering)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "transformer = StandardScaler().fit(X) \n",
    "customers_scale = transformer.transform(X) \n",
    "customers_scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 4 - Agrupación de datos con K-Means\n",
    "\n",
    "Ahora vamos a agrupar los datos con K-Means primero. Inicia el modelo K-Means, luego ajusta tus datos escalados. En los datos devueltos por el método `.fit`, hay un atributo llamado `labels_` que es el número de cluster asignado a cada registro de datos. Lo que puede hacer es asignar estas etiquetas de nuevo a `customers` en una nueva columna llamada `customers['labels']`. Entonces verá los resultados de cluster de los datos originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from yellowbrick.cluster import KElbowVisualizer\n",
    "\n",
    "# Instantiate the KMeans model\n",
    "# random_state=42 is used for reproducibility of results\n",
    "km = KMeans(random_state=42)\n",
    "\n",
    "# Instantiate the KElbowVisualizer with the KMeans model\n",
    "# k=(2,10) indicates the range of number of clusters to try (from 2 to 10)\n",
    "visualizer = KElbowVisualizer(km, k=(2,10))\n",
    "\n",
    "# Fit the visualizer to the data\n",
    "# This will run K-means clustering for each value of k and calculate the distortion score for each\n",
    "clustering = visualizer.fit(customers_scale)\n",
    "\n",
    "# Render the plot\n",
    "# The Elbow plot displays the distortion score for each k\n",
    "# The point where the distortion score starts to level off ('elbow') is the recommended number of clusters\n",
    "visualizer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_labels = pd.Series(clustering.labels_)\n",
    "print('Número de clusters:', km_labels.nunique())\n",
    "km_labels.value_counts()\n",
    "\n",
    "# Conclusión: El código de arriba nos devuelve los datos para el máximo valor de k que el algoritmo debe de haber probado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A ver qué nos da Silhouette\n",
    "from yellowbrick.cluster import SilhouetteVisualizer\n",
    "\n",
    "# Setting up the matplotlib figure with multiple subplots\n",
    "fig, ax = plt.subplots(5, 2, figsize=(15,8))\n",
    "\n",
    "# Loop through different numbers of clusters (from 2 to 5)\n",
    "for i in [2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "    # Create KMeans instance for different number of clusters\n",
    "    # 'k-means++' for smart centroid initialization, 10 different centroid initializations\n",
    "    # 100 iterations max for each run, and set a random state for reproducibility\n",
    "    km = KMeans(n_clusters=i, init='k-means++', n_init=10, max_iter=100, random_state=42)\n",
    "\n",
    "    # Determine the position of the subplot\n",
    "    q, mod = divmod(i, 2)\n",
    "\n",
    "    # Create a SilhouetteVisualizer with the KMeans instance\n",
    "    # Colors are set to 'yellowbrick' palette, and the subplot ax is defined\n",
    "    visualizer = SilhouetteVisualizer(km, colors='yellowbrick', ax=ax[q-1][mod])\n",
    "\n",
    "    # Fit the visualizer to the data to produce the silhouette plot\n",
    "    visualizer.fit(customers_scale)\n",
    "\n",
    "# Display the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viendo el elbow pododríamos escoger 2 como el número de clusters correctos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hmmm... En realidad el codo estaba en k = 7.... O como mucho en k = 5.... k = 2 ???\n",
    "kmeans_2 = KMeans(n_clusters=2).fit(customers_scale)\n",
    "\n",
    "labels = kmeans_2.predict(customers_scale)\n",
    "\n",
    "clusters = kmeans_2.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole['labels'] = clusters\n",
    "whole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuenta los valores en `labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Valores en labels (literalmente):', len(labels))\n",
    "print('Valores únicos de cluster:', whole['labels'].nunique())\n",
    "whole['labels'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 5 - Clustering de datos con DBSCAN\n",
    "\n",
    "Ahora vamos a agrupar los datos utilizando DBSCAN. Utiliza `DBSCAN(eps=0.5)` para iniciar el modelo y, a continuación, ajusta los datos escalados. En los datos devueltos por el método `.fit`, asigna las `labels_` de nuevo a `customers['labels_DBSCAN']`. Ahora tus datos originales tienen dos etiquetas, una de K-Means y la otra de DBSCAN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN \n",
    "\n",
    "# Applying DBSCAN\n",
    "# eps: The maximum distance between two samples for them to be considered as in the same neighborhood\n",
    "# min_samples: The number of samples in a neighborhood for a point to be considered as a core point\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "clusters = dbscan.fit_predict(customers_scale)\n",
    "\n",
    "whole['labels_DBSCAN'] = clusters\n",
    "whole"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuenta los valores en `labels_DBSCAN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Valores en labels (literalmente):', len(clusters))\n",
    "print('Valores únicos de cluster:', whole['labels_DBSCAN'].nunique())\n",
    "whole['labels_DBSCAN'].value_counts()\n",
    "\n",
    "# N.B. -1 in clusters represents outliers detected by DBSCAN !!! \n",
    "# Esta etiqueta significa que no encajan bien en ningún cluster basándose en los valores de `eps` y `min_samples`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reto 6 - Comparar K-Means con DBSCAN\n",
    "\n",
    "Ahora queremos comparar visualmente cómo K-Means y DBSCAN han agrupado nuestros datos. Crearemos gráficos de dispersión para varias columnas. Para cada uno de los siguientes pares de columnas, traza un gráfico de dispersión utilizando `labels` y otro utilizando `labels_DBSCAN`. Ponlos uno al lado del otro para compararlos. ¿Qué algoritmo de agrupación tiene más sentido?\n",
    "\n",
    "Columnas a visualizar:\n",
    "\n",
    "* `Detergents_Paper` as X and `Milk` as y\n",
    "* `Grocery` as X and `Fresh` as y\n",
    "* `Frozen` as X and `Delicassen` as y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualice `Detergentes_Papel` como X y `Leche` como Y mediante `labels` y `labels_DBSCAN` respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_scaled = pd.DataFrame(customers_scale, columns=whole.columns[:-2])\n",
    "whole_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def plot(x,y,hue):\n",
    "#     sns.scatterplot(x=x, \n",
    "#                     y=y,\n",
    "#                     hue=hue)\n",
    "#     plt.title('Detergents Paper vs Milk ')\n",
    "#     return plt.show();\n",
    "\n",
    "def plot(x,y,hue,axs,num):\n",
    "    sns.scatterplot(x=whole_scaled.loc[:, x], \n",
    "                    y=whole_scaled.loc[:, y],\n",
    "                    c=hue, cmap='viridis', marker='o', edgecolor='k', s=50, ax=axs[num])\n",
    "    axs[num].set_xlabel(x + ' (scaled)')\n",
    "    axs[num].set_ylabel(y + ' (scaled)')    \n",
    "    return #plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 7))\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 8), sharey=True)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.97]) #rect=[left, bottom, right, top]\n",
    "\n",
    "# Método A) Scaled X, como en los apuntes\n",
    "# plt.scatter(customers_scale[:, 6], customers_scale[:, 3], c=clusters, cmap='viridis', marker='o', edgecolor='k', s=50)\n",
    "\n",
    "# Método B) X\n",
    "# plt.scatter(whole.loc[:, 'Detergents_Paper'], whole.loc[:, 'Milk'], c=clusters, cmap='viridis', marker='o', edgecolor='k', s=50)\n",
    "\n",
    "# Método A mejorado) Scaled X using function\n",
    "#plot('Detergents_Paper', 'Milk', clusters, 'Detergents_Paper vs Milk')\n",
    "\n",
    "xcol = 'Detergents_Paper'\n",
    "ycol = 'Milk'\n",
    "plot(xcol, ycol, labels, axs, 0)  # K-Means\n",
    "plot(xcol, ycol, clusters, axs, 1)  # DBSCAN\n",
    "fig.suptitle(xcol + ' vs ' + ycol)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualice `Grocery` como X y `Fresh` como Y mediante `labels` y `labels_DBSCAN` respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20, 8), sharey=True)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.97]) #rect=[left, bottom, right, top]\n",
    "xcol = 'Grocery'\n",
    "ycol = 'Fresh'\n",
    "plot(xcol, ycol, labels, axs, 0)  # K-Means\n",
    "plot(xcol, ycol, clusters, axs, 1)  # DBSCAN\n",
    "fig.suptitle(xcol + ' vs ' + ycol)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualice `Frozen` como X y `Delicassen` como Y mediante `labels` y `labels_DBSCAN` respectivamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20, 8), sharey=True)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.97]) #rect=[left, bottom, right, top]\n",
    "xcol = 'Frozen'\n",
    "ycol = 'Delicassen'\n",
    "plot(xcol, ycol, labels, axs, 0)  # K-Means\n",
    "plot(xcol, ycol, clusters, axs, 1)  # DBSCAN\n",
    "fig.suptitle(xcol + ' vs ' + ycol)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a utilizar un groupby para ver cómo la media difiere entre los grupos. Agrupamos `customers` por `labels` y `labels_DBSCAN` respectivamente y calculamos las medias de todas las columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Valor promedio de todas las columnas:')\n",
    "whole.describe().iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole.groupby(['labels']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole.groupby(['labels_DBSCAN']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué algoritmo funciona mejor?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVACIONES**\n",
    "\n",
    "En la prueba que se ha realizado (K-Means con n-clusters=2, según ponía el enunciado y el código preexistente), parece que funciona mejor DBSCAN ya que los valores promedios de cada cluster están más cercanos a los valores promedios de las columnas. \n",
    "\n",
    "Podríamos probar K-Means con n-clusters=7, que quizá nos daría una clasificación más parecida a la que nos está dando DBSCAN.\n",
    "\n",
    "Por lo general, K-Means funciona bien con clusters bien definidos y sin mucho ruido (valores atípicos). Y, precisamente, no es el caso ya que los datos presentan bastantes valores atípicos, muy alejados del promedio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge 2 - Cambiar el número de clusters de K-Means\n",
    "\n",
    "Como hemos mencionado antes, no tenemos que preocuparnos por el número de clusters con DBSCAN porque lo decide automáticamente en función de los parámetros que le enviemos. Pero con K-Means, tenemos que suministrar el parámetro `n_clusters` (si no se suministra `n_clusters`, el algoritmo utilizará `8` por defecto). Debe saber que el número óptimo de clusters varía en función del conjunto de datos. K-Means puede funcionar mal si se utiliza un número incorrecto de clusters.\n",
    "\n",
    "En el aprendizaje automático avanzado, los científicos de datos prueban diferentes números de clusters y evalúan los resultados con medidas estadísticas (leer [aquí](https://en.wikipedia.org/wiki/Cluster_analysis#External_evaluation)). Hoy no vamos a utilizar medidas estadísticas, sino nuestros ojos. En las celdas de abajo, experimenta con distintos números de conglomerados y visualízalos con gráficos de dispersión. ¿Qué número de clusters parece funcionar mejor para K-Means?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_7 = KMeans(n_clusters=7).fit(customers_scale)\n",
    "labels_7 = kmeans_7.predict(customers_scale)\n",
    "clusters_7 = kmeans_7.labels_.tolist()\n",
    "\n",
    "whole['labels_k7'] = clusters_7\n",
    "\n",
    "print('Valores en labels (literalmente):', len(labels_7))\n",
    "print('Valores únicos de cluster:', whole['labels_k7'].nunique())\n",
    "whole['labels_k7'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20, 8), sharey=True)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.97]) #rect=[left, bottom, right, top]\n",
    "\n",
    "xcol = 'Detergents_Paper'\n",
    "ycol = 'Milk'\n",
    "plot(xcol, ycol, labels_7, axs, 0)  # K-Means n-clusters=7\n",
    "plot(xcol, ycol, clusters, axs, 1)  # DBSCAN\n",
    "fig.suptitle(xcol + ' vs ' + ycol)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20, 8), sharey=True)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.97]) #rect=[left, bottom, right, top]\n",
    "xcol = 'Grocery'\n",
    "ycol = 'Fresh'\n",
    "plot(xcol, ycol, labels_7, axs, 0)  # K-Means n-clusters=7\n",
    "plot(xcol, ycol, clusters, axs, 1)  # DBSCAN\n",
    "fig.suptitle(xcol + ' vs ' + ycol)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(20, 8), sharey=True)\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.97]) #rect=[left, bottom, right, top]\n",
    "xcol = 'Frozen'\n",
    "ycol = 'Delicassen'\n",
    "plot(xcol, ycol, labels_7, axs, 0)  # K-Means n-clusters=7\n",
    "plot(xcol, ycol, clusters, axs, 1)  # DBSCAN\n",
    "fig.suptitle(xcol + ' vs ' + ycol)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBSERVACIONES:**\n",
    "\n",
    "* Viendo los gráficos del k-means observo que estableciendo un número mayor de aglomerados consigue agrupar mejor los valores extremos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Challenge 3 - Cambiar `eps` y `min_samples` de DBSCAN\n",
    "\n",
    "Experimenta cambiando los parámetros `eps` y `min_samples` de DBSCAN. Mira cómo difieren los resultados con la visualización de gráficos de dispersión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tus observaciones aquí**\n",
    "\n",
    "    + El DBscan ajustado...\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
